{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG to Sound Project\n",
    "\n",
    "![](https://rickerevolte.de/favicon.png)\n",
    "\n",
    "This work in progress-project aims to extract information from EEG-Files to use them as a modifiers for sound emulating e.g. sythesizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a test on an unknown EEG File that has been delivered as a raw binary without nearly any supplemantary informations.\n",
    "First, make sure you are runnung python 3 and install all necessary packages via pip.\n",
    "This jupyter book is optimized for python 3.9.2\n",
    "I recommend creating a virtual environment for this.\n",
    "Need help?\n",
    "https://packaging.python.org/en/latest/tutorials/installing-packages/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do some ASCII-Sniffing in order to obtain Information out of our demofile's header. Let's set the path to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../demo_EEG/demofile.EEG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our demofile's size. We will need that size later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "    print(f\"{path} has the size of {len(data)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the function seek_ascii() with the 2 arguments path (string) and number (int) of bytes we want to seek for readable ascii code.\n",
    "We will then call that function later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seek_ascii(path, n):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read(n)\n",
    "    printable = []\n",
    "    cur = bytearray()\n",
    "    for b in data:\n",
    "        if 32 <= b <= 126:\n",
    "            cur.append(b)\n",
    "        else:\n",
    "            if len(cur) >= 4:\n",
    "                try:\n",
    "                    printable.append(cur.decode(\"ascii\", errors=\"ignore\"))\n",
    "                except:\n",
    "                    pass\n",
    "            cur = bytearray()\n",
    "    if len(cur) >= 4:\n",
    "        try:\n",
    "            printable.append(cur.decode(\"ascii\", errors=\"ignore\"))\n",
    "        except:\n",
    "            pass\n",
    "    return printable, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will only check the header. For this we are reading the first few bytes. You can change that amount by giving n another value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, \"rb\") as f:\n",
    "    data = f.read(n)\n",
    "    ascii_blocks, raw_head = seek_ascii(path, n=8192)\n",
    "    print(\"\\nGefundene lesbare ASCII-Blöcke (erste 8192 Bytes):\")\n",
    "    if not ascii_blocks:\n",
    "        print(\"  (keine lesbaren ASCII-Blöcke gefunden)\")\n",
    "    else:\n",
    "        for s in ascii_blocks:\n",
    "            print(\" -\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, we can see some readable information in our demo file, such as names and data, but not the important information we need to read our demo file correctly.\n",
    "The missing information is:\n",
    "Sampling rate\n",
    "Number and order of channels\n",
    "Data type (continuous, event-based)\n",
    "Byte order (endian)\n",
    "and more.\n",
    "In the following, we will take steps to obtain as much accurate information as possible in order to read, visualize, and continue working with our EEG file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import struct\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Parameter\n",
    "# ------------------------------------------------\n",
    "home = os.path.expanduser(\"~/Documents/CODE/playground/python-Neuro/myEEG/write_markers-events\")\n",
    "markers_csv = os.path.join(home, \"markers.csv\")\n",
    "events_txt = os.path.join(home, \"events.txt\")\n",
    "valid_markers_txt = os.path.join(home, \"valid_markers.txt\")\n",
    "EEG_FILE = \"../demo_EEG/demofile.EEG\"\n",
    "CHANNEL_NAMES = [\n",
    "    \"Fp1\",\"Fp2\",\"F3\",\"F4\",\"C3\",\"C4\",\"P3\",\"P4\",\"O1\",\"O2\",\n",
    "    \"F7\",\"F8\",\"T3\",\"T4\",\"T5\",\"T6\",\"Fz\",\"Cz\",\"Pz\"\n",
    "]\n",
    "SFREQ = 256.0\n",
    "N_BYTES_MARKERS = 8192\n",
    "EPOCH_TMIN, EPOCH_TMAX = -0.1, 0.5\n",
    "# ------------------------------------------------\n",
    "# Funktionen\n",
    "# ------------------------------------------------\n",
    "def detect_binary_offset(filename, min_offset=200, max_scan=20000):\n",
    "    \"\"\"Erkennt, wo der ASCII-Header endet und Binärdaten beginnen.\"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read(max_scan)\n",
    "\n",
    "    printable = np.array([(32 <= b <= 126 or b in (9, 10, 13)) for b in data])\n",
    "    byte_values = np.frombuffer(data, dtype=np.uint8)\n",
    "    window = 1024\n",
    "    threshold = 0.2\n",
    "    offset = None\n",
    "\n",
    "    for i in range(min_offset, len(data) - window, 32):  # 32-Byte Schritte\n",
    "        win = printable[i:i + window]\n",
    "        frac_printable = np.mean(win)\n",
    "        # print(frac_printable)\n",
    "        stddev = np.std(byte_values[i:i + window])\n",
    "        # typischerweise: Text = hohe ASCII-Quote, geringe Varianz\n",
    "        # Binärdaten = niedrige ASCII-Quote, hohe Varianz\n",
    "        if frac_printable < threshold and stddev > 20:\n",
    "            offset = i\n",
    "            break\n",
    "\n",
    "    if offset is None:\n",
    "        print(\"⚠️ Kein klarer Übergang erkannt – nehme Default 1024 Bytes\")\n",
    "        offset = 1024\n",
    "\n",
    "    print(f\"➡️  Binärdaten vermutlich ab Byte {offset}\")\n",
    "    with open(EEG_FILE, \"rb\") as f:\n",
    "        header = f.read(offset)  # erste Anzahl Bytes lesen\n",
    "        print(f\"header: \", header.decode(errors=\"ignore\"))  # zeigt ASCII-Inhalt\n",
    "    \n",
    "    return offset\n",
    "\n",
    "def extract_markers(path, n_bytes=N_BYTES_MARKERS, sfreq=SFREQ):\n",
    "    \"\"\"Extrahiere Marker aus den letzten Bytes der EEG-Datei.\"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        # print(\"This is f: \",f)\n",
    "        f.seek(-n_bytes, os.SEEK_END)\n",
    "        tail = f.read()\n",
    "        # print(f\"tail of {N_BYTES_MARKERS} bytes: \", tail)\n",
    "\n",
    "    # marker_re = re.compile(rb\"(IMPEDANZ-WERTE|Augen auf|Augen zu|HV Anfang|HV Ende)\")\n",
    "    marker_re = re.compile(rb\"(Augen auf|Augen zu|HV Anfang|HV Ende|IGNORED)\")\n",
    "    events = []\n",
    "    for m in marker_re.finditer(tail):\n",
    "        text = m.group(0).decode(\"latin1\")\n",
    "        start = m.start()\n",
    "        prefix = tail[start-8:start]\n",
    "        if len(prefix) >= 4:\n",
    "            idx = struct.unpack(\"<I\", prefix[0:4])[0]\n",
    "            onset = idx / sfreq\n",
    "            events.append((onset, text))\n",
    "    return events\n",
    "\n",
    "def markers_to_events(markers, sfreq):\n",
    "    \"\"\"Erzeuge MNE-kompatibles events-Array.\"\"\"\n",
    "    event_id = {}\n",
    "    events = []\n",
    "    for onset, desc in markers:\n",
    "        if desc not in event_id:\n",
    "            event_id[desc] = len(event_id) + 1\n",
    "        sample_idx = int(onset * sfreq)\n",
    "        events.append([sample_idx, 0, event_id[desc]])\n",
    "    return np.array(events, dtype=int), event_id\n",
    "\n",
    "def check_for_nans(evoked_dict):\n",
    "    \"\"\"Prüft NaNs in ERP-Daten.\"\"\"\n",
    "    valid_evokeds = {}\n",
    "    for cond, evoked in evoked_dict.items():\n",
    "        if np.isnan(evoked.data).any():\n",
    "            print(f\"⚠️  {cond}: enthält NaNs – wird übersprungen\")\n",
    "        else:\n",
    "            valid_evokeds[cond] = evoked\n",
    "    return valid_evokeds\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Hauptteil\n",
    "# ------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    # --- Rohdaten laden ---\n",
    "    print(f\"loading file: \", EEG_FILE)\n",
    "    OFFSET = detect_binary_offset(EEG_FILE)\n",
    "    data = np.fromfile(EEG_FILE, dtype=np.int16, offset=OFFSET) #dtype EEG Daten ist int16 - Verwendung von int64 viertelt die Dauer und Marker fallen raus\n",
    "    print(\"Länge data: \",len(data))\n",
    "    print(\"Size data: \",data.size)\n",
    "    n_channels = len(CHANNEL_NAMES)\n",
    "    print(\"data.size/n_channels: \",data.size/n_channels)\n",
    "    n_samples = data.size // n_channels\n",
    "    print(\"abgerundet: \",(n_samples))\n",
    "    data = data[: n_samples * n_channels] # liste\n",
    "    print(len(data))\n",
    "    print(\"index 0: \",data[0])\n",
    "    data = data.reshape(n_samples, n_channels).T # macht 2D Array aus Daten\n",
    "\n",
    "    # Optional: in µV umwandeln\n",
    "    data = data.astype(np.float64) * 0.195  # Beispiel-Skalierung, je nach Gerät\n",
    "    info = mne.create_info(CHANNEL_NAMES, SFREQ, ch_types=\"eeg\")\n",
    "    montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "    info.set_montage(montage)\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    # --- Marker extrahieren ---\n",
    "    markers = extract_markers(EEG_FILE, sfreq=SFREQ)\n",
    "    print(markers)\n",
    "    # markers = [(0.9, \"Bla\"), (1, \"Blo\"), (10, \"hier bin ich\")]\n",
    "    print(f\"\\nGefundene Marker: {len(markers)}\")\n",
    "    for whatever, wasanderes in markers:\n",
    "        print(f\"{whatever:.1f} s → {wasanderes}\")\n",
    "\n",
    "    # --- Marker außerhalb des gültigen Bereichs verwerfen ---\n",
    "    valid_markers = [(on, tx) for on, tx in markers if 0 <= on <= raw.times[-1]]\n",
    "    print(f\"\\nMarker innerhalb Datenbereich: {len(valid_markers)}\")\n",
    "    for onset, text in valid_markers:\n",
    "        print(f\"{onset:.3f} s → {text}\")\n",
    "    print(valid_markers) \n",
    "\n",
    "    # --- Annotationen ---\n",
    "    annotations = mne.Annotations(\n",
    "        onset=[on for on, _ in valid_markers],\n",
    "        duration=[1.0] * len(valid_markers),\n",
    "        description=[tx for _, tx in valid_markers]\n",
    "    )\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    raw.plot(n_channels=19, duration=10.0, scalings=\"auto\", block=True)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, just for demonstration, this section of code is the fully working, but still we are missing an important information, which is the correct order of the channels. Up to this point, we have applied standards that do not necessarily apply.\n",
    "Before we start looking for typical neurological responses to trigger events in another tutorial in order to assign the neurological responses to the corresponding stimulated brain areas, we will now take a detour to analyze the change in frequency over time.\n",
    "\n",
    "To be continued\n",
    "(Last updated: November 2025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 (ipykernel) - find me in '~/.pyenv/shims/python'",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
