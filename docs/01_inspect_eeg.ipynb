{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG to Sound Project\n",
    "\n",
    "![](https://rickerevolte.de/favicon.png)\n",
    "\n",
    "This work in progress-project aims to extract information from EEG-Files to use them as a modifiers for sound emulating e.g. sythesizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a test on an unknown EEG File that has been delivered as a raw binary without nearly any supplemantary informations.\n",
    "First, make sure you are runnung python 3 and install all necessary packages via pip.\n",
    "This jupyter book is optimized for python 3.9.2\n",
    "I recommend creating a virtual environment for this.\n",
    "Need help?\n",
    "https://packaging.python.org/en/latest/tutorials/installing-packages/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do some ASCII-Sniffing in order to obtain Information out of our demofile's header. Let's set the path to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../demo_EEG/demofile.EEG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our demofile's size. We will need that size later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../demo_EEG/demofile.EEG has the size of 11250464 bytes\n"
     ]
    }
   ],
   "source": [
    "with open(path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "    print(f\"{path} has the size of {len(data)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the function seek_ascii() with the 2 arguments path (string) and number (int) of bytes we want to seek for readable ascii code.\n",
    "We will then call that function later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seek_ascii(path, n):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read(n)\n",
    "    printable = []\n",
    "    cur = bytearray()\n",
    "    for b in data:\n",
    "        if 32 <= b <= 126:\n",
    "            cur.append(b)\n",
    "        else:\n",
    "            if len(cur) >= 4:\n",
    "                try:\n",
    "                    printable.append(cur.decode(\"ascii\", errors=\"ignore\"))\n",
    "                except:\n",
    "                    pass\n",
    "            cur = bytearray()\n",
    "    if len(cur) >= 4:\n",
    "        try:\n",
    "            printable.append(cur.decode(\"ascii\", errors=\"ignore\"))\n",
    "        except:\n",
    "            pass\n",
    "    return printable, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will only check the header. For this we are reading the first few bytes. You can change that amount by giving n another value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Readable ASCII blocks found (first 8192 Bytes):\n",
      " - COHERENCE\n",
      " - 27101553CB\n",
      " - Cooper\n",
      " - Dale\n",
      " - 22.02.1959M\n",
      " - Routine EEG\n",
      " - PRAXIS\n",
      " - !5 6!8!:!=!? \n",
      " - !a b!p5f!/6N%I$J%32Q\"V#U\"<]'\\ ]#\\z,n-i,j-\n",
      " - _i+y*~+}*\n",
      " - ,.,/\n",
      " - $.$/\n",
      " - <.</\n",
      " - 4.4/3.0/\n",
      " - /o.l/k.h/g.d/c.`/\n",
      " - .|/{.x/w.t/s.p/O.L/K.H/G.D/C.@/_.\\/[.X/W.T/S.P/\n",
      " - //.,/+.(/'.$/#. /?.</;.8/7.4/3.0/\n",
      " - /o.l/k.h/g.d/c.`/\n",
      " - .|/{.x/w.t/s.p/O.L/K.H/G.D/C.@/_.\\/[.X/W.T/S.P/\n",
      " - }.(/\n",
      " - u. /\n",
      " - m.8/\n"
     ]
    }
   ],
   "source": [
    "with open(path, \"rb\") as f:\n",
    "    data = f.read(n)\n",
    "    ascii_blocks, raw_head = seek_ascii(path, n=8192)\n",
    "    print(f\"\\nReadable ASCII blocks found (first {n} Bytes):\")\n",
    "    if not ascii_blocks:\n",
    "        print(\"  (Readable ASCII blocks found)\")\n",
    "    else:\n",
    "        for s in ascii_blocks:\n",
    "            print(\" -\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, we can see some readable information in our demo file, such as names and dates, but not the important information we need to read our demo file correctly.\n",
    "The missing information is:\n",
    "Sampling rate\n",
    "Number and order of channels\n",
    "Data type (continuous, event-based)\n",
    "Byte order (little-endian/big-endian)\n",
    "and more.\n",
    "In the following, we will take steps to obtain as much accurate information as possible in order to read, visualize, and continue working with our EEG file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to draw conclusions about the number of channels based on the file size, the approximate examination time, and various standard sizes as well as different types of data, e.g. 16 bit, 32 bit per sample.\n",
    "\n",
    "Our numerator is the size of our demofile.\n",
    "Our denominator will then be: number of channels * number of bytes per sample * samplingrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_duration(filesize, n_channels=(), dtype_bytes_options=()):\n",
    "    print(\"\\nDauerabschätzung (bei verschiedenen bytes/pro sample):\")\n",
    "    for nch in n_channels:\n",
    "        for bps in dtype_bytes_options:\n",
    "            seconds = filesize / (nch * bps * 256.0)  # using 256 Hz as example\n",
    "            mm = int(seconds // 60)\n",
    "            ss = int(seconds % 60)\n",
    "            print(f\" - number of channels={nch} / bytes/sample={bps}: {seconds:.2f} s  → {mm} min {ss} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume different numbers of channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels=(19,21,23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and different byte options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_bytes_options=(2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And will run the function guess_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250464\n"
     ]
    }
   ],
   "source": [
    "with open(path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "    filesize = len(data)\n",
    "    print(filesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dauerabschätzung (bei verschiedenen bytes/pro sample):\n",
      " - number of channels=19 / bytes/sample=2: 1156.50 s  → 19 min 16 s\n",
      " - number of channels=19 / bytes/sample=4: 578.25 s  → 9 min 38 s\n",
      " - number of channels=21 / bytes/sample=2: 1046.36 s  → 17 min 26 s\n",
      " - number of channels=21 / bytes/sample=4: 523.18 s  → 8 min 43 s\n",
      " - number of channels=23 / bytes/sample=2: 955.37 s  → 15 min 55 s\n",
      " - number of channels=23 / bytes/sample=4: 477.69 s  → 7 min 57 s\n"
     ]
    }
   ],
   "source": [
    "guess_duration(filesize, n_channels, dtype_bytes_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function endian_test will run some tests on our demofile in order to find out the most possible byte-order little- or big-endian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately our patient remembers a rough time estimation of ca 20 minutes and made a selfie during the examination in which we could see the EEG device with 23 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endian_test(path, n_channels=23, dtype='int16', n_samples_to_read=5000):\n",
    "    dt_size = np.dtype(dtype).itemsize\n",
    "    bytes_needed = n_channels * n_samples_to_read * dt_size\n",
    "    filesize = os.path.getsize(path)\n",
    "    if filesize < bytes_needed:\n",
    "        n_samples_to_read = max(1, filesize // (n_channels * dt_size))\n",
    "        bytes_needed = n_channels * n_samples_to_read * dt_size\n",
    "    print(f\"\\nendianness/statistical test: read first {n_samples_to_read} samples per channel (total {bytes_needed} Bytes).\")\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read(bytes_needed)\n",
    "    arr_le = np.frombuffer(raw, dtype='<i2')  # little-endian int16\n",
    "    arr_be = np.frombuffer(raw, dtype='>i2')  # big-endian int16\n",
    "    # try to reshape assuming interleaved samples (time major)\n",
    "    for name, arr in ((\"little-endian\", arr_le), (\"big-endian\", arr_be)):\n",
    "        if arr.size % n_channels != 0:\n",
    "            print(f\"  {name}: not divisible by {n_channels} (len={arr.size})\")\n",
    "            continue\n",
    "        arr2 = arr.reshape((-1, n_channels)).T  # shape (n_channels, n_times)\n",
    "        mins = arr2.min(axis=1)\n",
    "        maxs = arr2.max(axis=1)\n",
    "        means = arr2.mean(axis=1)\n",
    "        stds = arr2.std(axis=1)\n",
    "        print(f\"  {name}: samples total {arr.size}, per channel {arr2.shape[1]}\")\n",
    "        print(f\"    channel-min (first 5): {mins[:5].tolist()}\")\n",
    "        print(f\"    channel-max (first 5): {maxs[:5].tolist()}\")\n",
    "        print(f\"    channel-mean (first 5): {[round(x,2) for x in means[:5]]}\")\n",
    "        print(f\"    channel-std  (first 5): {[round(x,2) for x in stds[:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "endianness/statistical test: read first 5000 samples per channel (total 230000 Bytes).\n",
      "  little-endian: samples total 115000, per channel 5000\n",
      "    channel-min (first 5): [-32768, -32768, -32768, -32765, -32768]\n",
      "    channel-max (first 5): [32524, 32765, 32766, 32767, 32524]\n",
      "    channel-mean (first 5): [86.78, -93.25, -577.88, -295.54, -190.04]\n",
      "    channel-std  (first 5): [18893.33, 19013.95, 18868.42, 18810.12, 18634.51]\n",
      "  big-endian: samples total 115000, per channel 5000\n",
      "    channel-min (first 5): [-32512, -32255, -32051, -32512, -32255]\n",
      "    channel-max (first 5): [32716, 32000, 32257, 30068, 32558]\n",
      "    channel-mean (first 5): [1331.17, 1327.24, 1326.68, 1291.23, 1296.6]\n",
      "    channel-std  (first 5): [2736.18, 2756.21, 2791.56, 2794.53, 2786.64]\n"
     ]
    }
   ],
   "source": [
    "endian_test(path, n_channels=23, dtype='int16', n_samples_to_read=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are pretty sure about the total nuber of channels beeing 19, because of [\"FP1\",\"F3\",\"C3\",\"P3\",\"O2\",\"Fz\",\"Cz\",\"Pz\",\"O1\",\"F4\",\"C4\",\"P4\",\"FP2\",\"T3\",\"T4\",\"T5\",\"T6\",\"NE\",\"A1\",\"A2\",\"EX1\",\"EX2\",\"MISC\"] NE, A1, A2, EX1 and EX2 and MISC are mastoides for referencing and are usually not recorded. So I'm pretty sure about having here a standard 10-20 EEG with 19 channels.\n",
    "I will continue with this in the next book 02_readAndplotEEG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, just for demonstration, this section of code is the fully working, but still we are missing an important information, which is the correct order of the channels. Up to this point, we have applied standards that do not necessarily apply.\n",
    "Before we start looking for typical neurological responses to trigger events in another tutorial in order to assign the neurological responses to the corresponding stimulated brain areas, we will now take a detour to analyze the change in frequency over time.\n",
    "\n",
    "To be continued\n",
    "(Last updated: November 2025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 (ipykernel) - find me in '~/.pyenv/shims/python'",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
